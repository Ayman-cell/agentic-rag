# üß† Agentic RAG ‚Äì Recherche Documentaire + Web avec CrewAI

**Un syst√®me Agentic RAG qui combine recherche dans vos documents (PDF) + fallback web, orchestr√© par des agents CrewAI, avec support LLM local (Ollama) ou API.**

<div align="center">


[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-red?style=for-the-badge&logo=streamlit)](https://streamlit.io/)
[![CrewAI](https://img.shields.io/badge/CrewAI-Agents-black?style=for-the-badge)](https://docs.crewai.com/)
[![Qdrant](https://img.shields.io/badge/Qdrant-VectorDB-ff4d4d?style=for-the-badge&logo=qdrant)](https://qdrant.tech/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-000000?style=for-the-badge)](https://ollama.com/)

</div>

---

## üìã Vue d‚Äôensemble

Ce projet est une **impl√©mentation Agentic RAG** (Retrieval-Augmented Generation) construite autour de **CrewAI** :  
au lieu d‚Äôun pipeline statique ¬´ retrieve ‚Üí generate ¬ª, on orchestre un **workflow multi-agents** capable de :

- üîé **Chercher dans un PDF** (indexation locale + recherche s√©mantique)
- üåê **Basculer vers une recherche web** si la r√©ponse n‚Äôest pas trouv√©e dans les docs
- üß† **Synth√©tiser une r√©ponse** propre et structur√©e

üëâ Le projet inclut plusieurs variantes d‚Äôex√©cution :
- **Streamlit (Serper)** : recherche web via `SerperDevTool`
- **Streamlit (Local DeepSeek-R1)** : LLM local via `ollama/deepseek-r1` + web via FireCrawl
- **Streamlit (Local Llama 3.2)** : LLM local via `ollama/llama3.2` + web via FireCrawl

---

## ‚ú® Fonctionnalit√©s principales

### 1Ô∏è‚É£ Agentic RAG (CrewAI)
- ü§ñ Orchestration **multi-agents** (process s√©quentiel)
- üß© D√©composition des t√¢ches : **retrieval ‚Üí synthesis**
- üîÅ Workflow extensible (ajout d‚Äôoutils, routage, m√©moire, etc.)

### 2Ô∏è‚É£ Recherche dans vos documents (PDF)
- üìÑ Extraction texte PDF via **MarkItDown**
- üß† Chunking s√©mantique via **chonkie (SemanticChunker)**
- üì¶ Stockage vectoriel **Qdrant en m√©moire** (rapide pour d√©mos)

### 3Ô∏è‚É£ Fallback Web Search
- üîç Via **SerperDevTool** (Google-like search)
- üåê Ou via **FireCrawlWebSearchTool** (selon la variante)

### 4Ô∏è‚É£ Support LLM local (Ollama) ou API
- üß† Mod√®les locaux : `ollama/deepseek-r1`, `ollama/llama3.2`
- üîë Option API (selon configuration)

---

## üèóÔ∏è Architecture (simplifi√©e)

```
Utilisateur (Streamlit)
   ‚îÇ
   ‚ñº
Agent Retriever (CrewAI)
   ‚îú‚îÄ‚îÄ üìÑ DocumentSearchTool (PDF ‚Üí chunks ‚Üí Qdrant ‚Üí top matches)
   ‚îî‚îÄ‚îÄ üåê Web Search (Serper / FireCrawl)
   ‚îÇ
   ‚ñº
Agent Synthesizer (CrewAI)
   ‚îÇ
   ‚ñº
R√©ponse finale (citations/segments pertinents)
```

---

## üõ†Ô∏è Technologies utilis√©es

| Technologie | Utilisation |
|---|---|
| **CrewAI** | Orchestration d‚Äôagents + t√¢ches |
| **Streamlit** | Interface web interactive |
| **MarkItDown** | Extraction texte depuis PDF |
| **chonkie (SemanticChunker)** | D√©coupage s√©mantique des documents |
| **Qdrant (in-memory)** | Vector store pour la recherche |
| **SerperDevTool** | Recherche web |
| **FireCrawl** | Recherche web / crawling (selon variante) |
| **Ollama** | Ex√©cution de LLMs locaux |
| **Pydantic** | Sch√©mas d‚Äôentr√©es outils |

---

## üìã Pr√©requis

- Python **3.10+** (conforme au `pyproject.toml`)
- (Optionnel) **Ollama** si vous utilisez les variantes locales
- Cl√©s API selon votre mode :
  - `SERPER_API_KEY` (recherche web via Serper)
  - `FIRECRAWL_API_KEY` (web via FireCrawl)
  - `OPENAI_API_KEY` (si vous utilisez un mod√®le API)

---

## üöÄ Installation & D√©marrage

### 1Ô∏è‚É£ Cloner le d√©p√¥t
```bash
git clone https://github.com/Ayman-cell/agentic-rag.git
cd agentic-rag
```

### 2Ô∏è‚É£ Cr√©er un environnement virtuel
```bash
python -m venv .venv
# Windows
.\.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 3Ô∏è‚É£ Installer les d√©pendances
Le d√©p√¥t d√©clare `crewai[tools]` dans `pyproject.toml`.

```bash
pip install -e .
pip install streamlit markitdown "chonkie[semantic]" qdrant-client fastembed
```

> Astuce : si vous pr√©f√©rez, vous pouvez aussi installer directement :
> `pip install "crewai[tools]>=0.86.0,<1.0.0"`

---

## üîê Configuration (.env)

Cr√©ez un fichier `.env` (ou copiez `.env.example`) :

```bash
cp .env.example .env
```

Exemple (selon vos besoins) :

```dotenv
# Optionnel si vous utilisez OpenAI
MODEL=your_model_name
OPENAI_API_KEY=your_openai_api_key

# Recherche web Serper (app.py)
SERPER_API_KEY=your_serper_api_key

# Recherche web FireCrawl (apps locales)
FIRECRAWL_API_KEY=your_firecrawl_api_key
```

---

## ‚ñ∂Ô∏è Lancer l‚Äôapplication (Streamlit)

### Variante 1 ‚Äî Serper (web search via SerperDevTool)
```bash
streamlit run app.py
```

### Variante 2 ‚Äî Local DeepSeek-R1 (Ollama) + FireCrawl
```bash
streamlit run app_deep_seek.py
```

### Variante 3 ‚Äî Local Llama 3.2 (Ollama) + FireCrawl
```bash
streamlit run app_llama3.2.py
```

üìå Dans l‚ÄôUI Streamlit :
- uploadez un PDF dans la sidebar
- posez vos questions dans le chat
- le syst√®me tente d‚Äôabord le document, puis fallback web si n√©cessaire

---

## üß© Structure du projet

```
agentic-rag/
‚îú‚îÄ‚îÄ assets/                   # Images / ressources
‚îú‚îÄ‚îÄ knowledge/                # Documents (PDF) √† indexer
‚îú‚îÄ‚îÄ src/agentic_rag/
‚îÇ   ‚îú‚îÄ‚îÄ crew.py               # Agents + t√¢ches CrewAI (config YAML)
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Runner CLI (scripts pyproject)
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml       # R√¥les / objectifs agents
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml        # D√©finition des t√¢ches
‚îÇ   ‚îî‚îÄ‚îÄ tools/
‚îÇ       ‚îî‚îÄ‚îÄ custom_tool.py    # DocumentSearchTool (PDF ‚Üí Qdrant)
‚îú‚îÄ‚îÄ app.py                    # Streamlit (Serper)
‚îú‚îÄ‚îÄ app_deep_seek.py          # Streamlit (Ollama DeepSeek-R1 + FireCrawl)
‚îú‚îÄ‚îÄ app_llama3.2.py           # Streamlit (Ollama Llama 3.2 + FireCrawl)
‚îú‚îÄ‚îÄ agentic_rag.ipynb         # Notebook d√©mo
‚îú‚îÄ‚îÄ demo_llama3.2.ipynb       # Notebook d√©mo
‚îú‚îÄ‚îÄ .env.example              # Variables d‚Äôenvironnement
‚îî‚îÄ‚îÄ pyproject.toml            # D√©pendances + scripts
```

---

## üß† D√©tails : DocumentSearchTool

L‚Äôoutil `DocumentSearchTool` (dans `src/agentic_rag/tools/custom_tool.py`) :

- extrait le texte du PDF via **MarkItDown**
- cr√©e des chunks via **SemanticChunker** (`chonkie`)
- utilise un embedding model : `minishlab/potion-base-8M`
- stocke les chunks dans **Qdrant en m√©moire** (`QdrantClient(":memory:")`)
- renvoie les passages les plus pertinents pour la requ√™te

> ‚ö†Ô∏è Note : le mode `:memory:` est id√©al pour d√©mos/POC. Pour la production, utilisez un Qdrant persistant + gestion d‚ÄôIDs, m√©tadonn√©es et versions.

---

## üêõ Troubleshooting

- **Ollama ne r√©pond pas** : v√©rifiez que le service tourne (`http://localhost:11434`).
- **Aucune r√©ponse trouv√©e** : testez un PDF plus textuel / v√©rifiez que l‚Äôupload et l‚Äôindexation ont bien eu lieu.
- **Cl√© API manquante** : assurez-vous que `.env` est charg√© et que les variables sont d√©finies.

---

## ü§ù Contribution

PRs et issues bienvenues ‚úÖ  
Id√©es d‚Äôam√©liorations :
- persistance Qdrant (Docker) au lieu de `:memory:`
- citations + scores de retrieval
- √©valuation (RAGAS / tests de r√©gression)
- ajout reranking (cross-encoder)
- support multi-documents + metadata filtering

---

## üìù Licence

Voir le fichier `LICENSE` du d√©p√¥t.

---

**Derni√®re mise √† jour : 14 f√©vrier 2026**  
**Version : 0.1.0**
