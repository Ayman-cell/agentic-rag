
# Agentic RAG using CrewAI

This project leverages CrewAI to build an Agentic RAG that can search through your docs and fallbacks to web search in case it doesn't find the answer in the docs, have option to use either of deep-seek-r1 or llama 3.2 that runs locally. More details un Running the app section below!

Before that, make sure you grab your FireCrawl API keys to search the web.

**Get API Keys**:
   - [FireCrawl](https://www.firecrawl.dev/i/api)

### Watch Demo on YouTube
[![Watch Demo on YouTube](https://github.com/patchy631/ai-engineering-hub/blob/main/agentic_rag/thumbnail/thumbnail.png)](https://youtu.be/O4yBW_GTRk0)


## Installation and setup

**Get API Keys**:
   - [FireCrawl](https://www.firecrawl.dev/i/api)


**Install Dependencies**:
   Ensure you have Python 3.11 or later installed.
   ```bash
   pip install crewai crewai-tools chonkie[semantic] markitdown qdrant-client fastembed
   ```

**Running the app**:

To use deep-seek-rq use command ``` streamlit run app_deep_seek.py ```, for llama 3.2 use command ``` streamlit run app_llama3.2.py ```
# üöÄ NEXUS EXPLORERS - Plateforme IA de D√©tection d'Exoplan√®tes

**Syst√®me full-stack combinant Machine Learning, API REST et interface 3D pour la pr√©diction d'exoplan√®tes**

<div align="center">

## üåê **[D√âCOUVRIR L'APPLICATION](https://nexus-explorer-v10.vercel.app/)** üåê

[![Vercel](https://img.shields.io/badge/Deployed-Vercel-black?style=for-the-badge)](https://vercel.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15-black?style=for-the-badge&logo=next.js)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.103-009688?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)

---

## üîç Pr√©sentation

NEXUS EXPLORERS est une plateforme de recherche d'exoplan√®tes qui combine des mod√®les de Machine Learning, une API REST performante et une interface 3D interactive pour visualiser et explorer les candidats d√©tect√©s. Elle est con√ßue pour la recherche reproduisible, la d√©monstration et l'int√©gration rapide dans des pipelines scientifiques.

## ‚ú® Fonctionnalit√©s principales

- D√©tection et score de candidats exoplan√®tes via mod√®les ML entra√Æn√©s
- API REST (FastAPI) pour requ√™tes et int√©gration tierce
- Interface 3D et tableau de bord web (Next.js) pour visualisation interactive
- D√©ploiement pr√™t pour Vercel/Cloud avec CI minimal

## üß∞ Stack technique

- Frontend: Next.js / TypeScript
- Backend: FastAPI / Python
- Mod√®les: Python (scikit-learn, PyTorch, ou √©quivalent)<br/>
- Stockage: vector store / base de donn√©es l√©g√®re selon configuration

## üöÄ Installation rapide (d√©veloppeur)

Pr√©requis: Python 3.10+ et Node.js.

1. Cloner le d√©p√¥t

```bash
git clone <votre-repo>
cd agentic-rag
```

2. Installer les d√©pendances Python

```bash
python -m pip install -r requirements.txt
```

3. Lancer l'API (exemple)

```bash
uvicorn src.agentic_rag.main:app --reload
```

4. Lancer le frontend (si pr√©sent)

```bash
cd frontend && npm install && npm run dev
```

## üì¶ Usage

Consulter l'API via `http://localhost:8000/docs` pour tester les endpoints et utiliser l'interface web pour visualiser les r√©sultats.

## ü§ù Contribution

Toutes contributions sont les bienvenues : issues, PR, corrections de docs ou am√©liorations de mod√®le.

---

Si vous souhaitez que j'adapte ce README (ajout de badges, captures d'√©cran, instructions Windows sp√©cifiques, ou d√©tails d'installation exacts), dites-moi ce que vous voulez changer et je le ferai.
 
---

**Remarque importante :** le contenu ci‚Äëdessous d√©crit pr√©cis√©ment ce qui existe dans ce d√©p√¥t (`app.py`, `app_deep_seek.py`, `app_llama3.2.py`, `src/agentic_rag/`, etc.). Le projet est un prototype ¬´ Agentic RAG ¬ª construit autour de CrewAI et d'outils d'indexation de documents.

## Structure du d√©p√¥t

- `app.py` : application Streamlit principale (utilise `crewai` et `crewai_tools.SerperDevTool`). Permet d'uploader un PDF, l'indexer via `DocumentSearchTool` et interroger la crew.
- `app_deep_seek.py` : variante Streamlit utilisant un LLM local (ollama `deepseek-r1`) via `LLM` et `FireCrawlWebSearchTool` pour la recherche web.
- `app_llama3.2.py` : variante Streamlit utilisant un LLM local (ollama `llama3.2`) via `LLM` et `FireCrawlWebSearchTool`.
- `src/agentic_rag/` : code source principal du projet
   - `crew.py` : d√©finition de la `Crew` (`AgenticRag`) avec agents et t√¢ches configur√©s via `config/agents.yaml` et `config/tasks.yaml`.
   - `main.py` : petit runner CLI utilisable via `pyproject` scripts (`run`, `train`, `replay`, `test`).
   - `tools/custom_tool.py` : impl√©mentation de `DocumentSearchTool` (extraction PDF via `MarkItDown`, d√©coupage s√©mantique via `chonkie`, stockage dans Qdrant en m√©moire).
   - `config/agents.yaml` et `config/tasks.yaml` : configuration des agents et t√¢ches (prompts, r√¥les et objectifs).
- `knowledge/` : dossier pr√©vu pour les documents de connaissance (PDFs) ‚Äî utilis√© par l'outil d'indexation.
- `assets/` : images utilis√©es par les apps Streamlit (logos, miniatures).
- `demo_llama3.2.ipynb`, `agentic_rag.ipynb` : notebooks de d√©monstration et d'exploration.
- `.env.example` : variables d'environnement utiles (`OPENAI_API_KEY`, `SERPER_API_KEY`, `FIRECRAWL_API_KEY`, etc.).
- `pyproject.toml` : sp√©cifie `crewai[tools]` comme d√©pendance principale et d√©clare des scripts utiles.

## Fonctionnalit√©s montr√©es par le code

- Indexation d'un PDF en m√©moire et recherche par similarit√© (outil `DocumentSearchTool`).
- Flux multi‚Äëagent via CrewAI : un agent r√©cup√©rateur (retriever) et un agent synth√©tiseur (response synthesizer).
- Possibilit√© d'utiliser un LLM local via `LLM` (exemples : `ollama/deepseek-r1`, `ollama/llama3.2`) pour `app_deep_seek.py` et `app_llama3.2.py`.
- Recherche web via `SerperDevTool` ou `FireCrawlWebSearchTool` (la disponibilit√© d√©pend de vos cl√©s API et de la pr√©sence/impl√©mentation de ces outils).

## Pr√©requis

- Python 3.10+ (pyproject indique >=3.10)
- Node.js si vous comptez ajouter ou lancer un frontend s√©par√© (non fourni ici)
- Optionnel : Ollama ou autre endpoint LLM local si vous utilisez `app_deep_seek.py` / `app_llama3.2.py`.
- Variables d'environnement (voir `.env.example`) :

```dotenv
SERPER_API_KEY=your_serper_api_key
FIRECRAWL_API_KEY=your_firecrawl_api_key
OPENAI_API_KEY=your_openai_api_key  # si besoin
```

## Installation rapide

1. Cr√©ez et activez un environnement virtuel Python.

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

2. Installer les d√©pendances (exemple minimal √† adapter) :

```bash
pip install "crewai[tools]>=0.86.0,<1.0.0" markitdown chonkie qdrant-client streamlit uvicorn
```

Remarque : `pyproject.toml` d√©clare `crewai[tools]`; adaptez l'installation selon votre gestionnaire (pip/hatch).

## Lancement des applications Streamlit

- Interface g√©n√©rique (utilise `SerperDevTool`) :

```bash
streamlit run app.py
```

- Variante avec LLM local `deepseek-r1` :

```bash
streamlit run app_deep_seek.py
```

- Variante avec LLM local `llama3.2` :

```bash
streamlit run app_llama3.2.py
```

Dans les apps Streamlit :
- Uploadez un PDF via la sidebar ‚Äî l'application indexe le document avec `DocumentSearchTool` puis vous pouvez poser des questions (chat).
- Si vous utilisez une version LLM locale, assurez‚Äëvous que l'endpoint (`http://localhost:11434`) est bien accessible.

## Ex√©cution via `pyproject` (CLI)

Le `pyproject.toml` contient des scripts utiles que vous pouvez appeler apr√®s installation du paquet :

```bash
python -m pip install -e .
agentic_rag    # ex√©cute agentic_rag.main:run
```

Ou lancer directement les fonctions :

```bash
python -m src.agentic_rag.main run
```

## Note sur `DocumentSearchTool`

L'outil `src/agentic_rag/tools/custom_tool.py` :
- extrait le texte du PDF via `MarkItDown`;
- d√©coupe en chunks s√©mantiques via `chonkie` (embedding `minishlab/potion-base-8M` dans le code);
- stocke temporairement les vecteurs dans un client Qdrant en m√©moire (`QdrantClient(":memory:")`).

Cet outil est pr√©vu pour des exp√©rimentations locales et des petits PDF ; adaptez la strat√©gie de stockage/embeddings pour de la production.

## Contribution

- Issues et PR bienvenues. Pour proposer des am√©liorations, abordez :
   - ajouter un `requirements.txt` complet,
   - impl√©menter un backend Qdrant persistant,
   - ajouter des tests unitaires et des notebooks de reproduction.

---

Si vous voulez que je mette √† jour ce README avec des captures d'√©cran depuis `assets/`, que j'ajoute un `requirements.txt` exact ou que j'√©crive des instructions Windows plus d√©taill√©es (ex. commandes PowerShell pr√™tes √† copier), dites‚Äëmoi lesquelles et je m'en occupe.
